{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Important Note : Used for getting data from ony NetApp-DocV3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chargeback_rpt.db_postgres_command as db_command\n",
    "import chargeback_rpt.vm_data_utility as vm_util\n",
    "import chargeback_rpt.vm_data_validator as vx\n",
    "import chargeback_rpt.email_notifier as x_mail\n",
    "\n",
    "import chargeback_rpt.file_directory_manager as fd_mn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import sys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For run script .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_py=False\n",
    "fix_mmyy=True  #fix_mmyy=True  for test_only_jupyternotebook\n",
    "is_only_check_data=False\n",
    "\n",
    "x_datenow=datetime.datetime.now()\n",
    "month_x=x_datenow.strftime('%m')\n",
    "year_x=x_datenow.strftime('%Y')\n",
    "\n",
    "if fix_mmyy:\n",
    " month_param='09'\n",
    " year_param='2021'\n",
    "else:\n",
    " month_param=month_x\n",
    " year_param=year_x\n",
    "    \n",
    "    \n",
    "print(f\"Current month-year : {month_param}-{year_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  run_py:\n",
    "\n",
    "    press_y='n'\n",
    "    ok=False\n",
    "    \n",
    "    if len(sys.argv) > 1:\n",
    "        if sys.argv[1]=='0'  and sys.argv[2]=='0':\n",
    "         month_param=month_x\n",
    "         year_param=year_x \n",
    "         ok=True   \n",
    "         is_only_check_data=bool(int(sys.argv[3]))\n",
    "        else:\n",
    "         raise Exception(\"Specify 0 0 as arguments only\")   \n",
    "    else:\n",
    "        print(\"If you want current month and year.Press Enter \")\n",
    "        month_param = int(input(\"Enter the month (1-12) : \") or month_x)\n",
    "        year_param = int(input(\"Enter the year(such as 2021,2022,2023...) : \") or year_x)\n",
    "        print(f\"Do for month={month_param} and year={year_param}\")\n",
    "        press_y=input(f\"Press y=True and n=False : \") \n",
    "        if press_y.lower()=='y':\n",
    "         ok=True\n",
    "\n",
    "\n",
    "    if ok==True:\n",
    "        try:\n",
    "         report_dt= datetime.datetime(int(year_param), int(month_param), 1)\n",
    "         print(report_dt)   \n",
    "         month_param=report_dt.strftime('%m')\n",
    "         year_param=report_dt.strftime('%Y')   \n",
    "\n",
    "    #      n = len(sys.argv) \n",
    "    #      print(\"Total arguments passed:\", n) \n",
    "    #      for  param in  sys.argv:\n",
    "    #        print(param)\n",
    "\n",
    "        except Exception as ex:\n",
    "         print(ex)   \n",
    "         raise ex\n",
    "    else:\n",
    "         quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]\n",
    "\n",
    "size_col='size_used_gb_detail'  # column from sheet  FlexVolSpaceDetails\n",
    "size_col_2='size_used_gb'        #  column from shee FlexVolConfiguration\n",
    "\n",
    "\n",
    "VolConfiguration_sheet='netapp_vol'\n",
    "VolSpaceDetails_sheet='netapp_vol_details'\n",
    "\n",
    "vol_master_col='volume_name'\n",
    "vol_detail_col='volume_name_detail'\n",
    "svm_master_col='svm_name'\n",
    "svm_detail_col='svm_name_detail'\n",
    "\n",
    "extend_style='volume_extended_style'\n",
    "\n",
    "netapp_col_key='netapp'\n",
    "\n",
    "center_col='cost_center'\n",
    "system_col='system_name'\n",
    "created_date_col='created_date'\n",
    "\n",
    "comment_col='comment'\n",
    "\n",
    "\n",
    "key_summary='Total' \n",
    "\n",
    "total_col_vol='cluster_name'\n",
    "total_col_detail='cluster_name_detail'\n",
    "\n",
    "cs_cols_toCheck=[comment_col,center_col,system_col]\n",
    "#cs_cols_toCheck=[center_col,system_col]\n",
    "\n",
    "fiter_volDetail =['flexgroup','flexvol']\n",
    "\n",
    "key_audit_Vol='audit_vol_netapp'\n",
    "\n",
    "\n",
    "netapp_ok=False\n",
    "vol_filepath=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if is_only_check_data==False:\n",
    " t_id=vm_util.creating_transaction(2,month_param,year_param)\n",
    " \n",
    "else:\n",
    "  t_id=vm_util.creating_transaction(9,month_param,year_param)   \n",
    "    \n",
    "print(f\"ETL Transaction ID: {t_id}  and OnlyCheckData={is_only_check_data}\")    \n",
    "\n",
    "list_error=[]\n",
    "print(list_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move  to util\n",
    "def check_error_point_etl(tran_id):\n",
    "  print(list_error)\n",
    "  if True in list_error:\n",
    "\n",
    "        \n",
    "    etl_files=[]\n",
    "    if  vol_filepath is not None and os.path.exists(vol_filepath):\n",
    "     etl_files.append([netapp_ok,vol_filepath])   \n",
    "    \n",
    "    if len(etl_files)>0 and (netapp_ok==False) :\n",
    "     vm_util.finished_etl_folder(t_id,netapp_col_key,False,etl_files)  \n",
    "        \n",
    "    vm_util.collect_error_to_sent_mail(tran_id) \n",
    "    print(\"ETL occured error\") \n",
    "    \n",
    "    raise Exception(\"Program is teminated and check error from email and log_error.txt\")\n",
    "    \n",
    "  list_error.clear()\n",
    "  print(list_error)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Any Configvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    audit_vol_netapp=vm_util.get_config_value(key_audit_Vol,t_id)\n",
    "    print(audit_vol_netapp)\n",
    "    datetime_format = vm_util.get_config_value(\"datetime_format\", t_id)\n",
    "    print(datetime_format)\n",
    "    \n",
    "except Exception as ex:\n",
    "    list_error.append(True)\n",
    "    \n",
    "check_error_point_etl(t_id)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify all source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"get root folder\")\n",
    "\n",
    "key_path='import_path'\n",
    "import_path=vm_util.get_value_by_key(key_path)\n",
    "print(import_path)\n",
    "\n",
    "if import_path is not None:\n",
    " \n",
    " data_import_path=import_path['value']\n",
    " existPath,is_error=vx.check_existing_filepath(data_import_path,t_id)\n",
    " list_error.append(is_error)   \n",
    " if existPath:\n",
    "  print(\"Get Path of all source files: \",data_import_path)\n",
    "else:\n",
    " list_error.append(True)   \n",
    " error_message= f'no key:{key_path} in key column in config_value table'\n",
    " print(error_message)   \n",
    " vm_util.add_error_to_database(3,error_message,t_id)  \n",
    "    \n",
    "check_error_point_etl(t_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"get source file name for ready to do ETL\")\n",
    "\n",
    "sr_vol,is_error=vx.check_source_name_file(VolConfiguration_sheet,t_id)\n",
    "print(sr_vol)\n",
    "list_error.append(is_error)\n",
    "\n",
    "sr_detail,is_error=vx.check_source_name_file(VolSpaceDetails_sheet,t_id)\n",
    "print(sr_detail)\n",
    "list_error.append(is_error)\n",
    "check_error_point_etl(t_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load file and skip some rows\")\n",
    "print(sr_vol)\n",
    "vol_filepath=f\"{data_import_path}\\\\{sr_vol['source_prefix']}.{sr_vol['source_type']}\"\n",
    "a,is_error=vx.check_existing_filepath(vol_filepath,t_id)\n",
    "list_error.append(is_error)\n",
    "print(\"Get Path of volume file: \",vol_filepath,' is ',a)\n",
    "print(\"=======================================================================================================\")\n",
    "\n",
    "check_error_point_etl(t_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows_netapp=vm_util.get_value_by_key('skiprows_netapp')\n",
    "if skiprows_netapp is not None:\n",
    " skiprows=skiprows_netapp['value']\n",
    " skiprows_list = list(map(int, skiprows.split(',')))\n",
    " print('skip rows netapp: ',skiprows_list)\n",
    "else:\n",
    " list_error.append(True)   \n",
    " error_message= f'no key:{key_path} in key column in config_value table'\n",
    " print(error_message)   \n",
    " vm_util.add_error_to_database(3,error_message,t_id)  \n",
    "\n",
    "\n",
    "check_error_point_etl(t_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load volume and its detail\")\n",
    "\n",
    "sheet_name_list=[sr_vol['source_keyname'],sr_detail['source_keyname']]\n",
    "dict_dfs,is_error=vx.load_source_file_as_dict(vol_filepath,sheet_name_list,skiprows_list,t_id)\n",
    "\n",
    "df_vol=dict_dfs[sr_vol['source_keyname']]\n",
    "df_detail=dict_dfs[sr_detail['source_keyname']]\n",
    "\n",
    "check_error_point_etl(t_id) \n",
    "\n",
    "print(df_vol.head())\n",
    "print(df_detail.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selec required columns from dataframe and Mapping filed from datasouce to column dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Selec required columns from dataframe\")\n",
    "print(\"Mapping filed from datasouce to column dataframe\")\n",
    "\n",
    "\n",
    "print(f\"select columns in {VolConfiguration_sheet} sheet\")\n",
    "df_vol_mappingFields=vm_util.get_active_datafield(sr_vol['id'])\n",
    "\n",
    "# remove size used gb columne name from main sheet for getting from detail \n",
    "print(\"Remove {size_col_2}\")\n",
    "df_vol_mappingFields=df_vol_mappingFields.query('column_table_name!=@size_col_2')\n",
    "\n",
    "print(df_vol_mappingFields[['column_table_name','field_source_name','is_additional','datasource_id']])\n",
    "\n",
    "print(\"==================FlexVolConfiguration mappingFields==================================\")\n",
    "df_vol,err=vx.select_colunm_df_fieldname_ds(df_vol,df_vol_mappingFields['field_source_name'].tolist(),vol_filepath,t_id,)\n",
    "\n",
    "\n",
    "print(df_vol.tail())\n",
    "list_error.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping FlexVolConfiguration\")\n",
    "df_vol,err=vx.map_fields_ds_to_cols_df(df_vol,df_vol_mappingFields,vol_filepath,t_id)\n",
    "list_error.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"select columns in {VolSpaceDetails_sheet} sheet\")\n",
    "df_detail_mappingFields=vm_util.get_active_datafield(sr_detail['id'])\n",
    "\n",
    "#replace size column name  in FlexVolSpaceDetails  in order to advoice duplicatetion templorily\n",
    "df_detail_mappingFields.replace(size_col, size_col_2,  inplace=True)\n",
    "size_col=size_col_2\n",
    "print(df_detail_mappingFields[['column_table_name','field_source_name','is_additional','datasource_id']])\n",
    "\n",
    "\n",
    "print(\"==================FlexVolSpaceDetails mappingFields==================================\")\n",
    "df_detail,err=vx.select_colunm_df_fieldname_ds(df_detail,df_detail_mappingFields['field_source_name'].tolist(),vol_filepath,t_id,)\n",
    "print(df_detail.tail())\n",
    "list_error.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping FlexVolSpaceDetails\")\n",
    "df_detail,err=vx.map_fields_ds_to_cols_df(df_detail,df_detail_mappingFields,vol_filepath,t_id)\n",
    "list_error.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_error_point_etl(t_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove last row summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"remove last row summary\")  \n",
    "def remove_summary_row(total_col,dfx):\n",
    " idx_last=dfx.tail(-1).query(f'{total_col}==@key_summary').index\n",
    " if(len(idx_last)>0):\n",
    "  dfx.drop(index=idx_last,inplace=True)\n",
    " return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vol=remove_summary_row(total_col_vol,df_vol)\n",
    "df_detail=remove_summary_row(total_col_detail,df_detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"========================={VolConfiguration_sheet}=================================\")\n",
    "print(df_vol.info())\n",
    "print(df_vol.head())\n",
    "print(df_vol.tail())\n",
    "print(f\"========================={VolSpaceDetails_sheet}=================================\")\n",
    "print(df_detail.info())\n",
    "print(df_detail.head())\n",
    "print(df_detail.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_error_point_etl(t_id) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Volumn Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Filter Volume Name By Excluding AuditVolume started with  {audit_vol_netapp}\")\n",
    "\n",
    "df_vol = df_vol[df_vol[vol_master_col].apply(lambda volName: not volName.lower().startswith(audit_vol_netapp.lower()))] \n",
    "print(df_vol.head())\n",
    "print(df_vol.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Volumn Detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filter Volume Extended Style only \",fiter_volDetail)\n",
    "df_detail=df_detail.query('volume_extended_style in @fiter_volDetail').sort_values(by=vol_detail_col, ascending=False)\n",
    "\n",
    "#print(df_detail[vol_detail_col].unique())\n",
    "\n",
    "print(df_detail.head())\n",
    "print(df_detail.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Volumn and its Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merge Volumn and its Detail\")\n",
    "try:\n",
    "     \n",
    "#  df_vol=df_vol.merge(df_detail[[vol_detail_col,size_col]],how='left',left_on=vol_master_col,right_on=vol_detail_col)\n",
    "#  df_vol.drop(columns=[vol_detail_col],inplace=True)\n",
    "   \n",
    "\n",
    " df_vol=df_vol.merge(df_detail[[svm_detail_col,vol_detail_col,size_col]], \n",
    "            how='left',left_on=[vol_master_col,svm_master_col],right_on=[vol_detail_col,svm_detail_col])\n",
    " df_vol.drop(columns=[vol_detail_col,svm_detail_col],inplace=True)\n",
    "  \n",
    "        \n",
    "except Exception as err:\n",
    " list_error.append(True)\n",
    " error_message= str(err)\n",
    " print(error_message)   \n",
    " vm_util.add_error_to_database(14,error_message,t_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_error_point_etl(t_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform &  Extract Volumn Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Cost Center and System Name and CreatedDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extract Cost Center and System Name and Created Date\")\n",
    "df_vol[center_col]=df_vol[comment_col].apply(vm_util.split_comment_to_each_value,args=(center_col,)) \n",
    "df_vol[system_col]=df_vol[comment_col].apply(vm_util.split_comment_to_each_value,args=(system_col,))\n",
    "df_vol[created_date_col]=df_vol[comment_col].apply(vm_util.split_comment_to_each_value,args=(created_date_col,))\n",
    "print(df_vol.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check invalid  data after extracting comment\")\n",
    "cols_na_comment,df_na_comment=vx.find_NaN(df_vol,cs_cols_toCheck)\n",
    "\n",
    "print(cols_na_comment)\n",
    "print(df_na_comment)\n",
    "\n",
    "if df_na_comment.shape[0]>0:\n",
    "    \n",
    " str_error = '</br>Summarize rows that found any null or incorrect format string in <b><u>comment column</u></b></br>'\n",
    " df_na_comment= df_na_comment.fillna(\"\")\n",
    " str_error += df_na_comment.to_html(index=False)\n",
    " vm_util.add_error_to_database(16, str_error,t_id)\n",
    " list_error.append(True)   \n",
    "\n",
    "\n",
    "check_error_point_etl(t_id) \n",
    "print(df_vol.info())\n",
    "print(df_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert string date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "lastDay_val=datetime.date(int(year_param),int(month_param),calendar.monthrange(int(year_param), int(month_param))[1])\n",
    "print(lastDay_val)\n",
    "print(\"Validate CreatedDate\")\n",
    "\n",
    "df_vol=vx.find_incorrrect_format_for_input_datetime(df_vol,created_date_col,vol_master_col,datetime_format,t_id)\n",
    "if df_vol is None:\n",
    " list_error.append(True)\n",
    " print(list_error)\n",
    "else:    \n",
    " df_vol=vx.find_invalid_x_date_greater_last_date_for_input_datetime(df_vol,created_date_col,lastDay_val,vol_master_col,t_id)\n",
    " if df_vol is None:\n",
    "  list_error.append(True) \n",
    "  print(list_error)\n",
    " else:\n",
    "   print(f\"all created_date > {lastDay_val}\")   \n",
    "   print( df_vol[[vol_master_col,created_date_col]] ) \n",
    "    \n",
    "check_error_point_etl(t_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform  additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Transform addtoinal data\")\n",
    "try:\n",
    "     \n",
    "\n",
    " df_vol['month']=month_param\n",
    " df_vol['year']=year_param\n",
    " df_vol['import_date']=x_datenow\n",
    "\n",
    "\n",
    " df_vol['transaction_id']= t_id\n",
    "\n",
    " #df_vol=df_vol.where(pd.notnull(df_vol), None) # replace nan with None then call replace_x_character\n",
    " df_vol['system_name']=df_vol['system_name'].apply(vx.replace_x_character)\n",
    " df_vol['cost_center']=df_vol['cost_center'].apply(vx.replace_x_character)   \n",
    "\n",
    "\n",
    "except Exception as err:\n",
    "  list_error.append(True)\n",
    "  error_message= str(err)\n",
    "  print(error_message)   \n",
    "  vm_util.add_error_to_database(14,error_message,t_id)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_error_point_etl(t_id) \n",
    "netapp_ok=True\n",
    "\n",
    "print(\"Last Check  prior to saving to database\")\n",
    "print(df_vol.info())\n",
    "print(df_vol[[vol_master_col,size_col,center_col,system_col,'created_date','month','year','import_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End up with  Completed ETL in only Checking Data mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_only_check_data==True:\n",
    "    try: \n",
    "\n",
    "        delete_resultList= fd_mn.delele_file(vol_filepath)   \n",
    "        updated_rows=vm_util.created_transaction(t_id)\n",
    "        print(\"completed ETL in only Checking Data mode\")\n",
    "        \n",
    "        exit()\n",
    "        \n",
    "        \n",
    "    except Exception as ex:\n",
    "        list_error.append(True)\n",
    "        print(ex)\n",
    "        raise Exception(\"Program is teminated and check error from email and log_error.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data to table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check columns matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_tb_key=\"storage_table\"\n",
    "table_name,listCols_report,is_error=vx.listCols_report_table(vm_tb_key,t_id)\n",
    "list_error.append(is_error)\n",
    "\n",
    "check_error_point_etl(t_id)\n",
    "print(f'list all columns in {table_name} table: ',len(listCols_report))\n",
    "print(listCols_report)\n",
    "\n",
    "\n",
    "print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "listCols_dfx=df_vol.columns.tolist()\n",
    "print(f'list all columns in {table_name} dataframe: ',len(listCols_dfx))\n",
    "print(listCols_dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns_2=vm_util.verify_existing_columns(listCols_dfx,listCols_report)\n",
    "\n",
    "print(check_columns_2)\n",
    "listCols_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Save data to database\")\n",
    "if check_columns_2  is None:\n",
    "   df_vol=df_vol[listCols_report]\n",
    "   print(df_vol.info())\n",
    "   #df_vol.to_excel('report_vol_before_DB.xlsx')\n",
    "   print(df_vol.head())\n",
    "   rslt=db_command.add_data_values(db_command.get_postgres_conn(),df_vol,table_name)\n",
    "   #print(rslt)\n",
    "    \n",
    "else:\n",
    "   list_error.append(True)\n",
    "   error_message=check_columns_2\n",
    "   vm_util.add_error_to_database(10,error_message,t_id)\n",
    "   print(error_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_error_point_etl(t_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update new cost center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Update new cost center\")\n",
    "\n",
    "try :\n",
    " cost_centerList = df_vol['cost_center'].unique()\n",
    " df_new_cc=vm_util.add_new_cost_center(cost_centerList,'NetApp-ETL',t_id)\n",
    " print(df_new_cc)\n",
    "except Exception as ex:\n",
    " list_error.append(True)   \n",
    " print(ex)   \n",
    "\n",
    "check_error_point_etl(t_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completed ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    etl_files=[[netapp_ok,vol_filepath]]\n",
    "    if netapp_ok==True :\n",
    "     vm_util.finished_etl_folder(t_id,netapp_col_key,True,etl_files)    \n",
    "     updated_rows=vm_util.created_transaction(t_id)\n",
    "     print(\"completed ETL\")\n",
    "    \n",
    "except Exception as ex:\n",
    "    list_error.append(True)\n",
    "    print(ex)\n",
    "    \n",
    "check_error_point_etl(t_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
